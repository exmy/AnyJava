#### 1. 认识事务

##### 1.1 为什么需要数据库事务

* 从数据库用户的观点来看，数据库中的一些操作的集合应该是一个独立单元，比如转账，但在数据库系统中，转账操作是由几个操作组成的，在执行转账操作过程中，可能会出现一下问题：

  * 转账操作的第一步执行成功，但是第二步执行失败或者未执行便发生系统宕机，导致转账失败但是A账户的钱减少了

  * 转账操作刚完成就发生系统宕机，系统重启恢复时丢失了宕机前的转账记录

  * 同时有另一个用户给B账户进行转账操作，由于同时对B账户进行操作，导致B账户金额出现异常
* 我们需要保证，这些操作要么全都发生、要么由于出错而全都不发生，事务就是为了解决这些问题

##### 1.2 什么是数据库事务

* 一个数据库操作序列（构成单一逻辑工作单元的操作集合），这些操作要么全做，要么全不做，是一个不可分割的单元

* 一个典型的数据库事务如下：

  ```sql
  BEGIN TRANSACTION;
  SQL1
  SQL2
  ...
  COMMIT/ROLLBACK
  ```

* 几点解释

  * 数据库事务可以包含一个或多个数据库操作，这些操作构成一个逻辑上的整体
  * 这些数据库操作，要么全部执行成功，要么全部不执行，要么全都对数据库产生影响，要么全都不产生影响，即不管事务是否执行成功，数据库总是能保持一致性状态
  * 以上即使在数据库出现故障以及并发事务存在的情况下依然成立

##### 1.3 事务如何解决问题

* 比如转账，所有的操作包含在一个事务中：

  ```sql
  BEGIN TRANSACTION   //开始事务
  A账户减少100元
  B账户增加100元
  COMMIT    //提交事务
  ```

  * 当这些操作失败或者系统出现异常时，数据库能够以事务为基本边界进行恢复，不会出现A账户金额减少而B账户未增加的情况
  * 当有多个用户同时操作数据库时，数据库能够以事务为单位进行并发控制，多个用户同时向B账户转账也不会导致错误

* 总结：事务使系统能够更方便的进行故障恢复以及并发控制，从而保证数据库状态的一致性

##### 1.4 事务的ACID特性

* 原子性(Atomicity)：事务中的所有操作作为一个整体像原子一样不可分割，要么全部成功，要么全部失败
* 一致性(Consistency)：事务的执行结果必须使数据库从一个一致性状态到另一个一致性状态。
  * 一致性状态是指：
    * 系统的状态满足数据的完整性约束(主码，参照完整性，check约束等) 
    * 系统的状态反应数据库本应描述的现实世界的真实状态，比如转账前后两个账户的金额总和应该保持不变
  * 说数据库处于一致性状态是指，数据库中只包含成功事务提交的结果
* 隔离性(Isolation)：并发执行的事务之间不能相互影响，其对数据库的影响应和它们串行执行时一样
* 持久性(Durability)：事务一旦提交，它对数据库的更新就是永久的。接下来的任何事务或系统故障都不会对其执行结果有任何影响。

##### 1.5 如何实现事务的ACID

* 一致性时事务的根本追求，而对数据一致性的破坏主要来自两个方面：
  * 事务的并发执行，不同事务的操作交叉执行
  * 事务故障或系统故障
* 事务的ACID实现是靠数据库的**并发控制技术**和**日志恢复技术**
  * 并发控制技术：保证事务的**隔离性**和**一致性**，使事务并发执行时数据的一致性状态不会被破坏
  * 日志恢复技术：保障事务的**原子性**，使数据库的一致性状态不会因各种故障而被破坏。同时使提交的事务修改不会因系统故障而丢失，保证了事务的**持久性**

#### 2. 数据库的并发控制技术

##### 2.1 常见的并发异常

事务并发执行时如果操作的是不同数据，没有问题，如果操作的是同一个数据，可能会导致数据的不一致，这就是**并发异常**现象，主要有以下几种：

* P0 丢失更新(Lost Update)
  * 第一类丢失更新，**回滚覆盖**，即脏写：事务T1修改了数据项，而另一个事务T2在T1回滚之前就修改了T1修改的数据项，导致T2脏写。一句话描述，**事务回滚了其他事务对数据的已提交更新**。如图：

    ![](https://github.com/exmy/CSNotes/raw/master/pics/%E8%84%8F%E5%86%99.png)

    * 注：脏写是任何隔离等级都需要必须避免的异常。

  * 第二类丢失更新，**提交覆盖**：事务1对A的修改覆盖了事务2对A的修改，导致事务2对A的修改好像丢失了一样。一句话描述，**事务覆盖了其他事务对数据的已提交更新**。如图：

    ![](https://github.com/exmy/CSNotes/raw/master/pics/%E4%B8%A2%E5%A4%B1%E6%9B%B4%E6%96%B02.png)

* P1 脏读(Dirty Read)：**一个事务读取了另一个事务未提交的数据**。如图，在事务1对A的处理过程中，事务2读取了A的值，但之后事务1回滚导致事务2读取的A是未提交的数据。

  ![](https://github.com/exmy/CSNotes/raw/master/pics/%E8%84%8F%E8%AF%BB.png)

* P2 不可重复读(Non-repeatable read)：**在一个事务中对同一数据的读取结果前后不一致**。如图，由于事务2对A的已提交修改，事务A前后两次读取的结果不一致。

  ![](https://github.com/exmy/CSNotes/raw/master/pics/%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB.png)

  * 脏读与不可重复读的区别在于：脏读读取的是**事务未提交**的数据，不可重复读读取的是**事务已提交**的数据

* P3 幻读(Phantom)：**事务读取某个范围的数据时，因为其他事务的操作导致前后两次读取的数据不一致**。如图，事务1查询A<5的数据，由于事务2插入了一条A=4的数据，导致事务1两次查询得到的结果不一样。

  ![](https://github.com/exmy/CSNotes/raw/master/pics/%E5%B9%BB%E8%AF%BB.png)

  * 幻读与不可重复读的区别在于：不可重复读针对**确定的某一行数据**，幻读针对**不确定的多行数据**
  * 幻读通常出现在**带有查询条件的范围查询**中

##### 2.2 事务的隔离级别

事务具有隔离性，理论上来说事务之间的执行不应该相互产生影响，其对数据库的影响应该和它们串行执行时一样。

然而完全的隔离性会导致系统并发性能很低，降低对资源的利用率，因而实际上对隔离性的要求会有所放宽，这也会在一定程度上造成对数据库的一致性要求降低。

SQL标准为事务定义了不同的隔离级别，从低到高依次是：

* 读未提交(Read Uncommitted)：除了脏写，其他并发异常都可能出现。
* 读已提交(Read Committed)：不会出现脏读，可能出现不可重复读、幻读、第二类丢失更新。
* 可重复读(Repeatable Read)：只可能出现幻读。
* 串行化(Serializable)：所有事务串行执行，不会出现并发异常。

如图：

![](https://github.com/exmy/CSNotes/raw/master/pics/%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB.png)

所有事务隔离级别都不允许出现脏写，而串行化可以避免所有可能出现的并发异常，但是会极大的降低系统的并发处理能力。

##### 2.3 事务隔离性的实现—并发控制技术

并发控制技术是实现事务隔离性以及不同隔离级别的关键，实现方式有很多，按照其对可能冲突的操作采取的不同策略可以分为**乐观并发控制**和**悲观并发控制**两大类。

* 乐观并发控制：对于并发执行可能冲突的操作，假定其不会真的冲突，允许并发执行，直到真正发生冲突时才去解决冲突，比如让事务回滚。
* 悲观并发控制：对于并发执行可能冲突的操作，假定其必定发生冲突，通过让事务等待(锁)或者中止(时间戳排序)的方式使并行的操作串行执行。

##### 2.4 常见的几种并发控制技术

**基于锁的并发控制**

* 核心思想：对于并发可能冲突的操作，通过加锁使它们互斥执行。
* 锁通常分为**共享锁**和**排他锁**两种类型。
  * 共享锁(S)：事务T对数据A加共享锁，其他事务只能对A加共享锁，不能加排他锁。
  * 排他锁(X)：事务T对数据A加共享锁，其他事务既不能对A加共享锁，也不能加排他锁。
* 基于锁实现的并发控制会阻塞**读-写、写-读、写-写**等可能发生冲突的操作，是一种**悲观并发控制策略**。
* 基于锁的并发控制流程：
  * 事务根据自己对数据项进行的操作类型申请相应的锁(**读申请共享锁，写申请排他锁**)
  * 申请锁的请求被发送给锁管理器，锁管理器根据当前数据项是否已经有锁以及申请的锁和持有的锁是否冲突，决定是否为该请求授予锁
  * 若锁被授予，则申请锁的事务可以继续执行；若被拒绝，则申请锁的事务将进行等待，直到锁被其他事务释放
* 可能出现的问题：
  * 死锁：多个事务持有锁并互相循环等待其他事务的锁导致所有事务都无法继续执行。
  * 饥饿：数据项A一直被加共享锁，导致事务一直无法获取A的排他锁。

**基于时间戳排序的并发控制**

* 核心思想：对于并发可能冲突的操作，基于时间戳排序规则选定某事务继续执行，其他事务进行回滚。
* 系统会在每个事务开始时赋予其一个时间戳，这个时间戳可以是系统时钟也可以是一个不断累加的计数器值，当事务回滚时会为其赋予一个新的时间戳，先开始的事务时间戳小于后开始事务的时间戳。
* 每一个数据项Q有两个时间戳相关的字段：
  * W-timestamp(Q)：成功执行write(Q)的所有事务的最大时间戳
  * R-timestamp(Q)：成功执行read(Q)的所有事务的最大时间戳
* 基于时间戳排序的并发控制流程：
  * 假设事务T发出read(Q)，T的时间戳为TS
    * 若`TS(T)<W-timestamp(Q)`，则T需要读入的Q已被覆盖。此read操作将被拒绝，T回滚。
    * 若`TS(T)>=W-timestamp(Q)`，则执行read操作，同时把R-timestamp(Q)设置为TS(T)与R-timestamp(Q)中的最大值
  * 假设事务T发出write(Q)，T的时间戳为TS
    * 若TS(T)<R-timestamp(Q)，write操作被拒绝，T回滚
    * 若TS(T)<W-timestamp(Q)，则write操作被拒绝，T回滚
    * 其他情况：系统执行write操作，将W-timestamp(Q)设置为TS(T)
* 基于时间戳排序和基于锁实现的**本质一样**：对于可能冲突的并发操作，**以串行的方式取代并发执行**，因而它也是一种**悲观并发控制**。它们的主要区别在于：
  * 基于锁是让冲突的事务**进行等待**，而基于时间戳排序是让冲突的**事务回滚**。
  * 基于锁冲突事务的执行次序是根据它们**申请锁的顺序**，而基于时间戳排序是根据**特定的时间戳排序规则**

**基于有效性检验的并发控制**

* 核心思想：事务对数据的更新首先在自己的工作空间进行，等到要写回数据库时才进行有效性检查，对不符合要求的事务进行回滚。
* 基于有效性检查的事务执行过程会被分为三个阶段：
  * 读阶段：数据项被读入并保存在事务的局部变量中。所有write操作都是对局部变量进行，并不对数据库进行真正的更新。
  * 有效性检查阶段：对事务进行有效性检查，判断是否可以执行write操作而不违反可串行性。如果失败，则回滚该事务。
  * 写阶段：事务已通过有效性检查，则将临时变量中的结果更新到数据库中。
* 有效性检查通常也是通过对事务的时间戳进行比较完成的，不过和基于时间戳排序的规则不一样。
* 该方法允许可能冲突的操作并发执行，因为每个事务操作的都是自己工作空间的局部变量，直到有效性检查阶段发现了冲突才回滚。因而这是一种**乐观并发控制策略**。

**基于快照隔离的并发控制**

* 快照隔离是**多版本并发控制**(mvcc)的一种实现方式。

* 核心思想：数据库为每个数据项维护多个版本(快照)，每个事务只对属于自己的私有快照进行更新，在事务真正提交前进行有效性检查，使得事务正常提交更新或者失败回滚。
* 由于快照隔离导致事务看不到其他事务对数据项的更新，为了避免出现丢失更新问题，可以采用以下两种方案避免：
  * 先提交者获胜：对于执行该检查的事务T，判断是否有其他事务已经将更新写入数据库，是则T回滚否则T正常提交。
  * 先更新者获胜：通过锁机制保证第一个获得锁的事务提交其更新，之后试图更新的事务中止。
* 事务间可能冲突的操作通过数据项的不同版本的快照而相互隔离，到真正要写入数据库时才进行冲突检测。因而这也是一种**乐观并发控制策略**。

#### 3. 数据库的日志恢复技术

##### 3.1 为什么需要日志恢复技术

数据库在运行过程中可能会出现故障，这些故障主要包括**事务故障**和**系统故障**两大类。

* 事务故障：比如非法输入，系统出现死锁，导致事务无法继续执行。
* 系统故障：比如由于软件漏洞或硬件错误导致系统终止。

这些故障可能会对事务和数据库状态造成破坏，因而必须提供一种技术来对各种故障进行恢复，保证数据库一致性，事务的原子性以及持久性，这种技术就是**日志恢复技术**。

##### 3.2 故障对事务破坏的例子

事务的执行流程如下：

* 系统会为每个事务开辟一个私有工作区。
* 事务读操作将从磁盘中拷贝数据项到工作区中，在执行写操作前所有的更新都作用于工作区中的拷贝。
* 事务的写操作将把数据输出到内存的缓冲区中，等到合适的时间再由缓冲区管理器将数据写入到磁盘。

由于数据库存在不同的修改策略，所以在事务执行过程中可能存在以下情况：

* 在事务提交前出现故障，但是事务对数据库的部分修改已经写入磁盘数据库中。这导致了**事务的原子性被破坏**。
* 在系统崩溃前事务已经提交，但数据还在内存缓冲区中，没有写入磁盘。系统恢复时将丢失此次已提交的修改。这导致了**事务持久性被破坏**。

##### 3.3 日志的种类和格式

日志文件是用来记录事务对数据库的更新操作的文件。

日志文件主要有两种格式：

* 以记录为单位的日志文件，这种文件中需要记录的内容包括：

  * 各个事务的**开始/结束标记**

  * 各个事务的**所有更新操作**

    每个日志记录的内容包括：

    * 事务标识（标明是哪个事务）
    * 操作类型（插入、删除、修改）
    * 操作对象
    * 更新前数据的旧值（插入操作，此项为空值）
    * 更新后数据的心智（删除操作，此项为空值）

* 以数据块为单位的日志文件

为保证数据库是可恢复的，登记日志文件时必须遵循两条原则：

* 登记的次序严格按照并发事务执行的时间次序
* 必须**先写日志文件，后写数据库**
  * 写日志和写数据库是两个不通过的操作，这两个操作之间可能发生故障
  * 如果先写数据库，发生了故障，导致日志文件没有登记这个修改，以后也无法恢复这个故障
  * 如果先写日志，发生了故障，还没写数据库，按日志文件恢复时只不过是多执行一次UNDO操作

日志的格式：

* <T, X, V1, V2>：描述一次数据库写操作，T是执行写操作的事务的唯一标识，X是要写的数据项，V1是数据项的旧值，V2是数据项的新值。

* <T, X, V1>：对数据库写操作的撤销操作，将事务T的X数据项恢复为旧值V1。在事务恢复阶段插入。

* <T start>：事务T开始

* <T commit>：事务T提交

* <T abort>：事务T中止

说明：

系统在对数据库进行修改前在会在日志文件末尾追加相应的日志记录。

当一个事务的commit日志记录写入到磁盘成功后，称这个事务已提交，但事务所做的修改可能并未写入磁盘。

##### 3.4 日志恢复

撤销事务undo：将事务更新的所有数据项恢复为日志中的旧值。

重做事务redo：将事务更新的所有数据项恢复为日志中的新值。

事务正常回滚或因事务故障中止将进行redo。

系统从崩溃中恢复时将先进行redo再进行undo。

事务故障的恢复（**撤销此事务已对数据库进行的修改**）：

* 反向扫描日志文件，查找该事务的更新操作。
* 对该事务的更新操作执行逆操作。
* 继续反向扫描日志文件，查找该事务的其他更新操作，做同样处理。
* 直至读到此事务的开始标记，事务故障恢复就完成了。

系统故障的恢复（**撤销故障发生时未完成的事务，重做已完成的事务**）：

* 正向扫描日志文件，找出在故障前已经提交的事务，将其事务标识记入重做队列(redo-list)，同时找出故障发生时还没有完成的事务，将其事务标识记入撤销队列(undo-list)
* 对撤销队列中的各个事务进行撤销(undo)处理
  * 反向扫描日志文件，对每个撤销事务的更新操作执行逆操作
* 对重做队列中的各个事务进行重做(redo)处理
  * 正向扫描日志文件，对每个重做事务重新执行日志文件登记的操作

带有检查点的恢复技术

* 在日志文件中增加一类新的记录——检查点记录，增加一个重新开始文件，并让恢复子系统在登陆日志文件期间动态的维护日志。
* 检查点记录的内容包括：
  * 建立检查点时刻所有正在执行的事务清单
  * 这些事务最近一个日志记录的地址
* 使用检查点方法可以改善恢复效率

![](https://github.com/exmy/CSNotes/raw/master/pics/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%E6%80%BB%E7%BB%93.png)

#### 参考资料

* [数据库系统那些事](https://zhuanlan.zhihu.com/p/38217080)
* [事务并发的可能问题与其解决方案](https://juejin.im/entry/5846a2d361ff4b006ba8b2cd)
* 《数据库系统概念》